** https://doka.guide/tools/microservices/

Микросервис — это отдельное приложение, как правило, очень небольшое, которое
поддерживает ограниченную функциональность. С помощью программного интерфейса (API)
такое приложение встраивается практически в любой продукт и может работать в составе
разных продуктов одновременно. Микросервисы часто противопоставляют монолитам, крупным
приложениям, которые полностью реализуют большой набор функций. Особенностью монолитов
является глубокое зацепление разных частей приложения и, как следствие, худшие
характеристики масштабируемости в сравнении с микросервисами.
Например, приложение, которое рассылает письма по списку адресов электронной почты,
или приложение, которое проводит аутентификацию пользователей, или приложение,
которое отслеживает активность пользователей в сервисе, — отличные кандидаты,
чтобы стать микросервисами. Можно повторять разработку похожего набора функций
для нового продукта, а можно реализовать и отладить микросервис или несколько
микросервисов, которые будут работать корректно для любого приложения.
Традиционно существовала концепция приложения, которое полностью решает все задачи
программного продукта — монолит. В эпоху быстрого развития рынка IT стало важным
уменьшить показатель time-to-market — время доведения до потребителя новой
функциональности или продукта. 
Практика разбиения программ на модули, которые можно переиспользовать в других программах,
оказалась успешной. Сначала на стороне сервера (бэкенд), потом и на стороне клиента
(фронтенд), части приложения стали выносить не только в отдельные модули, но и в
отдельные самостоятельные программы. Это позволило переиспользовать прошедшую проверку
временем функциональность в новых продуктах. Так и пришли к новому понятию — микросервис.

Плюсы микросервисов:
● Можно использовать тот стек технологий, который больше всего подходит для решения
поставленной задачи.
● Проще и дешевле разрабатывать набор микросервисов, в сравнении с разработкой
большого приложения.
● Поддерживать микросервисы намного проще и дешевле, чем поддерживать большое приложение.
● Не приходится каждый раз отлаживать работу для новых продуктов.
● Легко масштабировать приложение, построенное как совокупность микросервисов.
● Отказ одного сервиса не приводит к остановке системы в целом. Когда же ошибка
исправлена, необходимое изменение можно развернуть только для соответствующего
сервиса — вместо повторного развертывания всего приложения.
● Есть возможность использовать разные подходы к тестированию и доработки
каждого микросервиса.

Минусы микросервисов:
● Нужно поддерживать контракт — формализацию возможностей и условий взаимодействия
с микросервисом.
● Должна быть достаточно высокой квалификация разработчиков и инженеров по инфраструктуре.
● Микросервис должен минимально зависеть от контекста использования, не всегда это возможно.
● Могут возникать коллизии при обращении к одним и тем же сервисам: к базе данных,
к оперативной памяти, к диску, к процессору и прочим ресурсам.
● Сложно поддерживать и тестировать большое количество микросервисов.
● Разрабатывать большое количество микросервисов иногда дороже разработки монолита.

Когда применять
● Нужно держать высокую нагрузку. Проблемы пикового трафика легко решаются с помощью
микросервисов, существуют готовые решения и облачные сервисы, которые обеспечивают
автомасштабирование приложения. Сервисы добавляют ресурсы нагруженным микросервисам
или создают копии.
● Выросла команда разработки. Команда уже больше 10-15 человек и постоянно растёт,
новичков становится сложнее погружать во все тонкости разработки. Микросервисы могут
упростить командную работу и привести к единому набору стандартов разработки.
● В приложении появилось много модулей. Модулей уже несколько десятков, они достаточно
автономны, перевод их в микросервисы позволит легче масштабировать приложение
в будущем или переиспользовать при разработке новых продуктов.
● Стало очень много кода. Если приложение становится очень большим, то разбиение на
микросервисы упростит его поддержку и развитие.
● Нужно загружать приложение быстрее. Если приложение запускается несколько минут,
микросервисы позволят оптимизировать загрузку и применить масштабирование для
непроизводительных или высоконагруженных частей программы. Кроме этого, разработчики
тоже не будут ждать длительной сборки приложения и его загрузки на этапе отладки.
● Нужно использовать ресурсы компьютера оптимально. Модули могут обращаться к сети,
к памяти или к процессору неравномерно. Применение микросервисов позволит
оптимизировать этот компонент в работе приложения.
● Нужно быстро выводить новые продукты на рынок. Нужно обеспечить минимальное время
выхода на рынок новых продуктов и новых функций для уже существующих, микросервисы
обеспечат максимальную скорость развёртывания.

https://mcs.mail.ru/blog/prostym-jazykom-o-mikroservisnoj-arhitekture

Микросервисы и SOA не одно и то же. К SOA относится множество других шаблонов,
среди которых: CORBA, web-сервисы, очереди сообщений, ESB. Поэтому микросервисы стоит
воспринимать как конкретный подход к SOA, но не единственный.
Рассмотрим для примера типичный интернет-магазин. Монолитное приложение для него будет
использовать наверняка знакомую вам трехуровневую архитектуру, включающую:
1. пользовательский интерфейс;
2. серверную часть, отвечающую за бизнес-логику приложения и доступ к данным;
3. базу данных.
Мы видим, что бизнес-функции приложения очень разнообразны: работа с каталогом товаров
и корзиной, обработка заказов, их оплата и отслеживание статуса, ведение пользователей
и так далее. Но на уровне приложения все они объединены в один монолитный блок.
При разворачивании код для различных функций находится на одном сервере.
Чтобы масштабировать приложение, вам необходимо запустить несколько его экземпляров
на различных физических серверах.
Если монолитное приложение проще всего сравнить с кирпичной кладкой, то микросервисы
похожи на всем знакомый конструктор Lego. У вас есть множество деталей с четкими
стандартными границами для соединения друг с другом. Вы всегда можете пересобрать
получившееся изделие, заменив или убрав какие-то из элементов без ущерба для остальных.
Каждый из сервисов отвечает за конкретную бизнес-задачу, имеет собственное хранилище
данных и общается с другими сервисами через простые API-интерфейсы для решения более
сложных задач. Так, в нашем примере можно выделить микросервисы по ведению каталога
товаров, работе с корзиной, оформлению заказов, оплате и так далее.

** https://cloud.yandex.ru/blog/posts/2022/03/microservice-architecture

Какие инструменты использовать для создания микросервисов и работы с ними
1. Один из самых популярных способов создавать микросервисы — платформа контейнеризации
Docker. С его помощью приложение отделяется от инфраструктуры: это значит, что вы
сможете беспроблемно перемещаться между облачным и локальным хранилищем.
2. Чтобы оркестрировать контейнеры, то есть управлять работой с ними, чаще всего
используют кластеры Kubernetes.
3. Неотъемлемая часть любого микросервисного проекта — балансировщик.
Именно благодаря ему такую архитектуру считают более устойчивой к отказам,
чем монолитную: он контролирует, чтобы нагрузка на приложение распределялась по
облачным ресурсам равномерно.
** https://habr.com/ru/company/vk/blog/320962/
Микросервисная архитектура — это подход к созданию приложения, подразумевающий отказ
от единой, монолитной структуры. То есть вместо того чтобы исполнять все ограниченные
контексты приложения на сервере с помощью внутрипроцессных взаимодействий,
мы используем несколько небольших приложений, каждое из которых соответствует какому-то
ограниченному контексту. Причём эти приложения работают на разных серверах и
взаимодействуют друг с другом по сети, например посредством HTTP.
Иными словами, мы инкапсулируем определённые контексты приложения в микросервисы,
по одному на каждый, а сами микросервисы крутим на разных серверах.

Непрерывное развёртывание
Возможность и нацеленность на постоянное ускорение работы
● Быстро вводить в эксплуатацию: быстро развёртывать новые машины для разработки,
тестирования, приёмки и работы.
● Быстро развёртывать приложения: автоматически и быстро развёртывать наши сервисы.

Опять же, в старые добрые времена компании использовали архитектуру
Enterprise Service Bus (сервисная шина), при которой формируется канал коммуникаций
между эндпойнтами и бизнес-логикой. Затем этот подход преобразился в spaghetti box.
Микросервисная архитектура переносит бизнес-логику в конечные точки и использует
простые способы взаимодействия вроде HTTP.

Фронтенд/бэкенд
Есть два подхода к структурированию фронтенда и бэкенда при микросервисной архитектуре:

● Раскидать все части пользовательского интерфейса по микросервисам и сохранять
взаимосвязи между соответствующими микросервисами. Это позволяет наладить
внутрипроцессное взаимодействие между фронтендом и бэкендом. Но тогда будет очень сложно,
если вообще возможно, поддерживать связность UI. В случае перекрёстных изменений границ
в UI нам придётся одновременно обновлять несколько микросервисов, создавая взаимосвязи
и нарушая изолированность и независимость микросервисов, обеспечиваемые самой
архитектурой. Получается практически антипаттерн!
● Раскидать кодовые базы фронтенда и бэкенда, оставив UI приложения одним целым,
чтобы они потом взаимодействовали по HTTP. Микросервисы будут отделены друг от друга,
что дополнительно разделит фронтенд и бэкенд. Зато UI можно поддерживать целиком,
легко сохраняя его связность.

** https://habr.com/ru/post/249183/
Термин «Microservice Architecture» получил распространение в последние несколько лет
как описание способа дизайна приложений в виде набора независимо развертываемых сервисов.
В то время как нет точного описания этого архитектурного стиля, существует некий общий
набор характеристик: организация сервисов вокруг бизнес-потребностей, автоматическое
развертывание, перенос логики от шины сообщений к приемникам (endpoints) и
децентрализованный контроль над языками и данными.
архитектурный стиль микросервисов — это подход, при котором единое приложение строится
как набор небольших сервисов, каждый из которых работает в собственном процессе и
коммуницирует с остальными используя легковесные механизмы, как правило HTTP.
Эти сервисы построены вокруг бизнес-потребностей и развертываются независимо с
использованием полностью автоматизированной среды.

Архитектура микросервисов использует библиотеки, но их основной способ разбиения
приложения — путем деления его на сервисы. Мы определяем библиотеки как компоненты,
которые подключаются к программе и вызываются ею в том же процессе, в то время как
сервисы — это компоненты, выполняемые в отдельном процессе и коммуницирующие между
собой через веб-запросы или remote procedure call (RPC).
Главная причина использования сервисов вместо библиотек — это независимое развертывание.
Если вы разрабатываете приложение, состоящее из нескольких библиотек, работающих
в одном процессе, любое изменение в этих библиотеках приводит к переразвертыванию
всего приложения. Но если ваше приложение разбито на несколько сервисов, то изменения,
затрагивающие какой-либо из них, потребуют переразвертывания только изменившегося сервиса.
Конечно, какие-то изменения будут затрагивать интерфейсы, что, в свою очередь,
потребует некоторой координации между разными сервисами, но цель хорошей архитектуры
микросервисов — минимизировать необходимость в такой координации путем установки
правильных границ между микросервисами, а также механизма эволюции контрактов сервисов.

Микросервисный подход к разбиению подразумевает разбиение на сервисы в соответствии
с потребностями бизнеса. Такие сервисы включают в себя полный набор технологий,
необходимых для этой бизнес-потребности, в том числе пользовательский интерфейс,
хранилице данных и любые внешние взаимодействия. Это приводит к формированию
кросс-функциональных команд, имеющих полный набор необходимых навыков:
user-experience, базы данных и project management.

При выстраивании коммуникаций между процессами мы много раз были свидетелями того,
как в механизмы передачи данных помещалась существенная часть логики.
Хорошим примером здесь является Enterprise Service Bus (ESB).
ESB-продукты часто включают в себя изощренные возможности по передаче, оркестровке
и трансформации сообщений, а также применению бизнес-правил.
Комьюнити микросервисов предпочитает альтернативный подход: умные приемники сообщений
и глупые каналы передачи.
Вместо сложных протоколов, таких как WS-* или BPEL, они используют простые
REST-овые протоколы.
Два наиболее часто используемых протокола — это HTTP запросы через API ресурса
и легковесный месседжинг. легковесная шина сообщений. Такая инфраструктура как правило
не содержит доменной логики — простые реализации типа RabbitMQ или ZeroMQ не делают
ничего кроме предоставления асинхронной фабрики. Логика при этом существует на концах
этой шины — в сервисах, которые отправляют и принимают сообщения.

** https://habr.com/ru/company/maxilect/blog/677128/ Способы общения микросервисов
Синхронные способы общения - мы делаем вызов и ждем получения ответа:

1. Синхронный REST-like и аналоги. В чистом виде REST встречается редко, но в целом он
один из самых популярных. При желании через костыли его можно сделать “асинхронным”,
но этот случай мы тут не будем рассматривать.
● gRPC - RPC на бинарном формате сообщений поверх HTTP/2 от Google.
● SOAP - RPC с форматом XML. Это решение очень любили использовать в энтерпрайзе, оно
чаще встречается в более старых системах.

2. Асинхронные способы общения - мы отправляем сообщение, а ответ придет когда-нибудь
потом или он в принципе не предусмотрен:
● Месседжинг - RabbitMQ, ZeroMQ, ActiveMQ.
● Стриминг - Kafka. 

REST API
90% сервисов работает на REST API. Его так любят, потому что:
● Нужен минимум библиотек как клиенту, так и серверу. HTTP у нас и так работает,
в JSON можно писать / читать string.
● Легко вызвать API с фронта, легко прочитать ответ сервера из JS с помощью JSON.parse().
● Легкий старт для потребления API - узнал endpoint, посмотрел пример
запроса / ответа и можно начинать общение.
● Текстовый формат - легко дебажить и логировать, видя, что у него внутри в сообщении.
● Админы любят - можно заглядывать в данные HTTP-запроса и что-то с ними делать,
например настраивать роутинг трафика на основе данных http-запросов (L7)
или балансировку нагрузки по полю ID из запроса.
● Легкая для понимания синхронная парадигма “запрос-ответ”. Здесь нет подводных камней.
Ответ либо получен тут же, либо нет.
Но во всей этой простоте есть свои проблемы. Каждая из особенностей REST API,
которая делает его столь простым и популярным, на самом деле имеет оборотную сторону:
● Синхронный - если вызываемый сервис недоступен, нельзя отложить передачу или получение
информации на более позднее время. Если какой-то простой batch должен передать
сообщение и завершиться, но получатель лежит, будут проблемы.
● Peer-to-peer - нужно обращаться напрямую к искомому сервису. Более того, здесь нет
броадкастинга - если надо отправить одни и те же данные в пять разных сервисов,
придется сделать пять запросов. Сервисы получаются более связанными и могут погибать
в “волне отказов”.
● Текстовый - в JSON много лишних данных (ключи - значения), которые порождают
дополнительный трафик. Компрессия не позволяет сжать так, как хотелось бы, плюс
потребляет процессор. Для экономии некоторые пытаются называть ключи компактнее,
но глобально это не решает проблему.
● Нет схемы данных - вместо нее используют OpenAPI (Swagger), но он внедряется
не всегда и в целом это лишь свод рекомендаций, а не четкий закон.
Он может не соответствовать действительности.
● Концепция “все есть ресурс” может быть неудобна и непонятна части разработчиков.
Лично мне не нравится, что не все задачи легко решаются в рамках этой концепции.
Иногда не совсем понятно, как все уложить в понятие ресурса.
Есть уже прижившиеся способы описывать разные проблемные случаи,
вроде изменений статусов объектов. Но фактически это костыли.
● REST API - неплохое решение, когда нет высоких нагрузок и получается хорошо
контролировать доступность микросервисов. Взаимодействия по REST API проще отслеживать,
чем асинхронный обмен, - сразу видно, что ответ не приходит или приходит не в том формате.

gRPC:
● Использует бинарный формат Protobuf - утилизация трафика лучше, можно слать только
значения, не передавая ключи. Конечно, ты не можешь прочитать в консоли сообщение
глазами, как мог бы это сделать с JSON (приходится писать дополнительную утилиту,
которая будет его парсить перед тем, как прочитать). Зато на больших нагрузках
все это будет лучше работать.
● Есть схема данных, по которой генерируется DTO на запрос / ответ.
С жесткой схемой работать удобнее, Protobuf накладывает ограничения на изменение
схемы данных, чтобы сохранялась обратная совместимость. Это и плюс, и иногда минус.
● Можно передавать не один запрос, а слать объекты один за другим - стримить
● Есть встроенный механизм backpressure - если сообщения отправляются слишком быстро
и получатель не может их “переварить”, этот механизм позволяет замедлить передачу.
● Отправка запроса выглядит, как вызов метода в коде, - используется RPC-стиль.
gRPC подходит, если у вас в облаке крутится целый комбайн из кучи микросервисов,
которым надо между собой передавать много данных под высокой нагрузкой.
Для внешних пользователей он, конечно, не так удобен, как REST, но для внутреннего
общения это самое то, потому что здесь жестко фиксируется схема и потребляется меньше
трафика

Мессенджинг - RabbitMQ, ZeroMQ, ActiveMQ и Kafka:
Все перечисленные инструменты занимаются отправкой сообщений. Они очень разные,
но в целом верно следующее:
● Они обычно асинхронные. Шлешь сообщение и оно доставится когда-то в будущем.
Никакого “запрос-ответ”. Есть решения, где прямой очереди соответствует обратная
очередь для отправки ответа на сообщение, но это нельзя назвать синхронной историей.
● Бывают с брокером и без него. С моей точки зрения именно брокер дает слабую
связанность общению, правда, бывают кейсы, где все это реализуется очень медленно.
Поэтому брокер иногда считается оверхедом.
● С хранилищем (persistence) и без него (in-memory). В случае отказа брокер с хранилищем
(например, Kafka), который пишет все сразу на диск, ничего не потеряет. Правда, только
при условии, что вы позаботились настроить кластер как следует. Так можно хранить логи,
например за последние полгода. Но при чтении старых данных с диска все подтормаживает.
● С балансировкой нагрузки и без.
● Текстовые и бинарные.
● Со схемой данных или без нее.
● С одним получателем или с поддержкой броадкаста. Если честно, возможность броадкастинга
мне нравится больше всего - ты можешь реализовать модель издатель-подписчик,
когда тебе не интересно, кто подписался на тему. Твоя задача просто писать в нее
сообщения.
● С подтверждением получения и без него.
Kafka и прочие перечисленные инструменты - это дополнительный слой абстракции,
который обеспечивает асинхронность и отказоустойчивость. Он хорошо работает там,
где все это действительно востребовано - в сложной архитектуре с большим количеством
исполнителей, которых хочется подключать и отключать. Kafka умеет следить за тем,
чтобы сообщения не терялись, правильно все распараллеливать и реплицировать,
занимается дедупликацией при необходимости.
Оборотная сторона медали в том, что в асинхронном взаимодействии сложнее разобраться.
Ответ не приходит сразу - он может не прийти вообще или появиться через несколько часов
в ответном топике. У нашей команды множество историй про Kafka, в том числе и связанных
с багами самой Kafka. Кажется, что у любого разработчика есть свои примеры странного
поведения брокера.

** https://learn.microsoft.com/ru-ru/dotnet/architecture/microservices/architect-microservice-container-applications/microservices-architecture

Само название предполагает, что архитектура микрослужб является подходом к созданию
серверного приложения как набора малых служб, Это означает, что архитектура микрослужб
главным образом ориентирована на серверную часть, несмотря на то, что этот подход также
используется для внешнего интерфейса. где каждая служба выполняется в своем процессе
и взаимодействует с остальными службами по таким протоколам, как HTTP/HTTPS, WebSockets
или AMQP. Каждая микрослужба реализует специфические возможности в предметной области
и свою бизнес-логику в рамках определенного ограниченного контекста,
должна разрабатываться автономно и развертываться независимо. Наконец, у каждой
микрослужбы должны быть соответствующие собственные модель данных и логика предметной
области (владение и децентрализованное управление данными); для каждой микрослужбы
могут применяться разные технологии хранилищ (SQL, NoSQL) и разные языки программирования.
Каково размера должна быть микрослужба? При разработке микрослужбы размер не должен
быть важным фактором. Главным должно быть создание слабо связанных служб, что позволяет
добавиться автономности при разработке, развертывании и масштабировании каждой службы.
Конечно же, при определении и проектировании микрослужб следует стремиться к тому,
чтобы они были как можно меньше, если только они не имеют слишком много прямых
зависимостей от других микрослужб. Внутренняя связанность микрослужбы и ее независимость
от других служб важнее ее размера.
Почему следует использовать архитектуру микрослужб? Если говорить кратко, то это
гибкость в долгосрочной перспективе. Микрослужбы обеспечивают превосходные возможности
сопровождения в крупных комплексных системах с высокой масштабируемостью за счет
создания приложений, основанных на множестве независимо развертываемых служб с 
втономными жизненными циклами.
Дополнительное преимущество в том, что микрослужбы можно масштабировать независимо.
Вместо монолитного приложения, которое нужно масштабировать как единое целое, вы
масштабируете отдельные микрослужбы. Тем самым можно масштабировать только
функциональную область, требующую больше вычислительных или сетевых ресурсов,
не затрагивая другие области приложения, которые на самом деле не нуждаются в
масштабировании. Таким образом можно сократить расходы, так как требуется меньше
оборудования.

1. Владение данными в каждой микрослужбе
Важное правило архитектуры микрослужб состоит в том, что каждая микрослужба должна быть
владельцем своих данных и логики предметной области. Так же как полнофункциональное
приложение является владельцем своих логики и данных, так и каждая микрослужба должна
быть владельцем своей логики и данных в рамках автономного жизненного цикла, причем
развертывание производится независимо для каждой микрослужбы.
Монолитное приложение, обычно с одной реляционной базой данных, имеет два важных
преимущества: транзакции, обладающие свойствами атомарности, согласованности,
изолированности и долговечности, и язык SQL. Оба этих преимущества распространяются
на все таблицы и данные, связанные с приложением. Такой подход позволяет легко писать
запросы, объединяющие данные из нескольких таблиц.
Но при переходе на архитектуру микрослужб получать доступ к данным становится сложнее.
Даже при использовании транзакций ACID в микрослужбах или ограниченном контексте важно
учитывать, что данные, принадлежащие каждой микрослужбе, являются частными для этой
микрослужбы и должны быть доступны только синхронно через соответствующие конечные точки
API (gRPC, SOAP и т. д.) или асинхронно через систему обмена сообщениями (AMQP и т. д.).
Инкапсуляция данных делает микрослужбы слабосвязанными, благодаря чему они могут
изменяться независимо друг от друга. Если бы несколько служб обращались к одним
и тем же данным, изменения схемы требовали бы согласованного изменения всех служб.
При этом автономность жизненного цикла микрослужб нарушалась бы. Однако распределенные
структуры данных означают невозможность выполнения транзакции, обладающей свойствами
атомарности, согласованности, изолированности и долговечности, в рамках нескольких
микрослужб. Из этого, в свою очередь, следует, что если бизнес-процесс охватывает
несколько микрослужб, необходимо обеспечивать итоговую согласованность.
Это гораздо сложнее в реализации, чем простые соединения SQL, поскольку невозможно
создать ограничения целостности или использовать распределенные транзакции между 
отдельными базами данных, как мы объясним позднее. Аналогичным образом многие другие
возможности реляционных баз данных недоступны в рамках нескольких микрослужб.
Если разбираться дальше, микрослужбы часто используют базы данных разных типов.
Современные приложения хранят и обрабатывают разнообразные типы данных, и реляционная
база данных — не всегда лучший выбор. В некоторых ситуациях база данных NoSQL,
например Azure CosmosDB или MongoDB, может иметь более удобную модель данных и
обеспечивать более высокую производительность и масштабируемость по сравнению
с базой данных SQL, например SQL Server или базой данных SQL Azure. В других случаях
реляционная база данных по-прежнему является оптимальным решением. По этой причине
в приложениях на основе микрослужб часто используется сочетание баз данных SQL и NoSQL.
Такой подход иногда называют разнородным хранением данных.

2. Распределенное управление данными
Определение границ каждой микрослужбы
Каждая микрослужба должна быть частью вашего приложения, и каждая микрослужба должна
быть автономной — здесь есть свои преимущества и свои недостатки. 
Например, пользователь может называться пользователем в контексте идентификации или
членства, клиентом — в контексте управления клиентами, покупателем — в контексте заказов
и т. д.
Как вы определяете границы между контекстами приложения с отдельной предметной областью
для каждого контекста, так же вы определяете границы каждой микрослужбы, ее модель
предметной области и данные. Всегда старайтесь свести к минимуму взаимозависимость
между этими микрослужбами. Далее в главе Определение границ модели предметной области
для каждой микрослужбы будет подробно рассматриваться это разграничение
и проектирование модели предметной области.
Создание запросов, которые извлекают данные из нескольких микрослужб
● Шлюз API. Для простого объединения данных из нескольких микрослужб с разными
базами данных рекомендуется использовать микрослужбу агрегирования — шлюз API.
Будьте осторожны при применении этого шаблона, поскольку он может стать слабым местом
вашей системы и нарушить принцип автономности микрослужб. Чтобы смягчить негативные
последствия, используйте несколько мелких шлюзов API для различных вертикальных
срезов или областей системы. 
● CQRS с таблицами запросов/чтения. Еще одно решение для объединения данных из
нескольких микрослужб — шаблон материализованного представления. При таком подходе
вы заранее создаете (готовите денормализованные данные до фактической отправки запросов)
таблицу, доступную только для чтения, с данными, принадлежащими нескольким микрослужбам.
Таблица имеет формат, соответствующий потребностям клиентского приложения.
Этот подход позволяет не только решить изначальную проблему (как отправлять запросы
в несколько микрослужб), но и значительно повысить производительность по сравнению
с использованием сложных соединений, поскольку у вас уже есть все необходимые приложению
данные в таблице запроса.

3. Как добиться согласованности между несколькими микрослужбами
Как мы уже говорили, данные микрослужбы принадлежат только ей, и получить их можно
только через API микрослужбы. Поэтому встает вопрос, как реализовать целостные
бизнес-процессы, сохраняя согласованность нескольких микрослужб.
Чтобы проанализировать эту проблему, рассмотрим пример из примера приложения
eShopOnContainers. Микрослужба каталога хранит сведения обо всех товарах, включая
их цены. Микрослужба корзины управляет временными данными о товарах, которые
пользователи добавляют в корзину, включая стоимость элементов на момент их добавления
в корзину. При обновлении цены товара в каталоге эта цена также должна обновляться
в активных корзинах, содержащих этот товар, кроме того, системе, наверное, следует
предупреждать пользователей о том, что цена определенного элемента изменилась
с тех пор, как они добавили его в свою корзину.
В гипотетической монолитной версии этого приложения при изменении цены в таблице
"Товары" подсистема каталога может просто использовать транзакцию ACID, чтобы обновить
текущую цену в таблице "Корзина".
Однако в приложении на базе микрослужб таблицы "Товар" и "Корзина" находятся
в соответствующих микрослужбах. Микрослужбы никогда не должны включать таблицы или
хранилища других микрослужб в свои транзакции, и в том числе в прямые запросы
Микрослужба каталога не должна напрямую изменять таблицу "Корзина", поскольку эта
таблица принадлежит микрослужбе корзины. Чтобы обновить сведения в микрослужбе корзины,
микрослужба каталога может использовать только итоговую согласованность, возможно
на основе асинхронной связи, например событий интеграции (взаимодействие на основе
сообщений и событий). 

4. Проектирование взаимодействия между границами микрослужб
Взаимодействие через границы микрослужб является настоящей проблемой. В этом контексте
взаимодействие не подразумевает выбор протокола (HTTP и REST, AMQP, обмен сообщениями
и так далее). Нужно подумать, какой стиль следует использовать и, особенно, насколько
микрослужбы должны зависеть друг от друга. В случае сбоя его последствия для системы
будут определяться степенью этой взаимозависимости.
Чаще всего используются службы на базе HTTP (REST), поскольку они очень простые.
Использовать HTTP можно. Но как именно? Если вы используете запросы и ответы HTTP
только для взаимодействия между микрослужбами и клиентскими приложениями или шлюзами API,
это нормально. Но если вы создаете длинные цепочки синхронных HTTP-вызовов для
взаимодействия через границы микрослужб, как если бы микрослужбы были объектами в
монолитном приложении, в конце концов в приложении возникнут проблемы.
Представьте, что клиентское приложение делает вызов HTTP API к отдельной микрослужбе,
например микрослужбе заказов. Если микрослужба заказов, в свою очередь, вызывает
дополнительные микрослужбы по протоколу HTTP в рамках одного цикла запросов и ответов,
вы создадите цепочку HTTP-вызовов. Поначалу это может казаться разумным. Но при таком
подходе следует учитывать несколько важных аспектов:
● Блокировка и низкая производительность. Поскольку HTTP-запросы синхронные по своей
природе, изначальный запрос не получит ответ, пока все внутренние HTTP-вызовы не
завершатся. Представьте, что число этих вызовов значительно возрастет и при этом
один из промежуточных HTTP-вызовов к микрослужбе будет заблокирован. Это негативно
отразится на производительности и масштабируемости приложения, ведь количество
HTTP-запросов увеличится.
● Взаимозависимость микрослужб и HTTP. Микрослужбы для бизнеса не следует объединять
друг с другом. В идеале они даже не должны "знать" о существовании других микрослужб.
Если приложение использует взаимозависимые микрослужбы, как в примере, добиться
автономности каждой микрослужбы будет практически невозможно.
● Сбой в одной микрослужбе. Если вы создали цепочку микрослужб, соединенную HTTP-вызовами,
при сбое одной микрослужбы (а сбой неизбежен) вся цепочка перестанет работать.
Система на базе микрослужб должна максимально сохранять работоспособность в случае
частичных сбоев. Даже если вы применяете логику, которая использует повторные попытки
с экспоненциальной задержкой или механизмы размыкания цепи, чем сложнее цепочки
HTTP-вызовов, тем сложнее применить стратегию обработки сбоев на базе HTTP.
Если внутренние микрослужбы взаимодействуют с помощью цепочек HTTP-запросов, как
описано выше, такое приложение можно назвать монолитным, но основанным на протоколе
HTTP, а не на механизмах внутреннего взаимодействия процессов.
Поэтому, чтобы повысить автономность и устойчивость микрослужб, следует как можно
реже использовать цепочки запросов и ответов для взаимодействия между микрослужбами.
Рекомендуется использовать только асинхронное взаимодействие для связи между
микрослужбами — асинхронное взаимодействие, управляемое сообщениями и событиями,
или (асинхронные) HTTP-опросы независимо от изначального цикла HTTP-запросов и ответов.

5. Сравнение шаблона шлюза API с прямым взаимодействием клиента и микрослужбы
-Прямое взаимодействие между клиентом и микрослужбой
Возможный подход — использование архитектуры с прямым взаимодействием между клиентом
и микрослужбой. При таком подходе клиентские приложения могут отправлять запросы к
некоторым микрослужбам напрямую
При таком подходе у каждой микрослужбы есть общедоступная конечная точка, иногда с
отдельным портом TCP для каждой микрослужбы. Например, определенная служба может иметь
следующий URL-адрес в Azure:
http://eshoponcontainers.westus.cloudapp.azure.com:88/
В рабочей среде на основе кластера этот URL-адрес будет указывать на подсистему
балансировки нагрузки кластера, которая, в свою очередь, распределяет запросы между
микрослужбами. В производственной среде можно использовать контроллер доставки
приложений, например шлюз приложения Azure между вашими микрослужбами и Интернетом.
Данный слой выступает как прозрачный уровень, который не только выполняет балансировку
нагрузки, но и защищает службы благодаря завершению SSL-запросов. Это уменьшает
нагрузку на узлах за счет разгрузки завершения SSL-запросов и других задач, активно
использующих ЦП, в шлюз приложений Azure. В любом случае подсистема балансировки
нагрузки и контроллер доставки приложений прозрачны с точки зрения логической
архитектуры приложения.
Архитектура прямого взаимодействия клиента и микрослужбы достаточно хорошо подходит
для небольших приложений на основе микрослужб, особенно если клиентское приложение
представляет собой веб-приложение на стороне сервера, например приложение MVC ASP.NET.
Однако при создании больших и сложных приложений на основе микрослужб (например, при
обработке десятков типов микрослужб) и особенно в том случае, если клиентские приложения
представляют собой удаленные мобильные приложения или одностраничные веб-приложения,
этот подход приводит к появлению нескольких проблем.
Взаимодействие с несколькими микрослужбами для создания одного окна пользовательского
интерфейса увеличивает число круговых путей через Интернет. Это увеличивает задержку
и сложности на стороне пользовательского интерфейса. В идеальном случае ответы должны
эффективно вычисляться на стороне сервера. Это сокращает задержки, так как можно
возвращать несколько фрагментов данных в параллельном режиме, и в некоторых
пользовательских интерфейсах данные можно отобразить сразу же после их появления.
Реализация вопросов безопасности и сквозной функциональности, например реализация
безопасности и проверки подлинности на каждой микрослужбе, может потребовать
значительных усилий. Один из возможных подходов состоит в том, чтобы разместить эти
службы на узле Docker или во внутреннем кластере, закрыв прямой доступ к ним извне,
и реализовать сквозную функциональность централизованно, например в шлюзе API.
Протоколы, используемые на стороне сервера (например, AMQP или двоичные протоколы),
не поддерживаются в клиентских приложениях. Поэтому запросы необходимо выполнять через
такие протоколы, как HTTP или HTTPS, а затем преобразовывать в другие протоколы.
Подход посредник может помочь в этой ситуации.
API нескольких микрослужб может быть не слишком хорошо приспособлено для удовлетворения
потребностей различных клиентских приложений. Например, потребности мобильного
приложения могут отличаться от потребностей веб-приложения. Для мобильных приложений
может потребоваться дополнительная оптимизация, чтобы повысить эффективность данных
ответов. Это можно сделать, агрегировав данные из нескольких микрослужб и возвращая
один набор данных. Также иногда можно исключить из ответа все данные, которые
не требуются мобильному приложению. И, конечно же, эти данные можно сжать.
Опять же, можно предусмотреть удобный интерфейс или API между микрослужбами
и мобильным приложением для этого сценария.
● Преимущества шлюза API над прямым взаимодействием клиента и микрослужбы
промежуточный слой или уровень для косвенного обращения (шлюз) будет полезен в
приложениях на основе микрослужб. Если у вас нет шлюзов API, клиентские приложения
должны отправлять запросы непосредственно к микрослужбам, что может вызывать описанные
ниже проблемы.
● Взаимозависимость. Без шлюза API клиентские приложения тесно связаны с внутренними
микрослужбами. Клиентскому приложению нужно знать, как обрабатываются в микрослужбах
разные функции приложения. По мере развития и рефакторинга внутренних микрослужб все
действия с ними воздействуют на обслуживание, так как приводят к критическим изменениям
клиентских приложений, которые обращаются напрямую к внутренним микрослужбам.
Клиентские приложения приходится часто обновлять, что усложняет процесс развития решения.
● Большое количество круговых путей. Для одной страницы (экрана) в клиентском приложении
может потребоваться несколько вызовов к разным службам. Это приводит к созданию
нескольких круговых путей по сети между клиентом и сервером, что значительно увеличивает
задержку. Объединения на промежуточном уровне позволяют повысить производительность
и улучшить взаимодействие с пользователем для клиентского приложения.
● Проблемы безопасности. Без шлюза все микрослужбы будут доступны извне, что значительно
увеличивает уязвимую зону, если не скрыть внутренние микрослужбы, не используемые
клиентскими приложениями напрямую. Чем меньше уязвимая зона, тем надежнее будет ваше
приложение.
● Проблемы сквозной функциональности. Каждая общедоступная микрослужба должна
самостоятельно обрабатывать такие задачи, как авторизация и шифрование SSL.
Во многих случаях эти задачи можно вынести на общий уровень, что позволяет упростить 
внутренние микрослужбы.
● Что представляет собой шаблон шлюза API?
При проектировании и разработке крупных или сложных приложений на основе микрослужб
с несколькими клиентскими приложениями рекомендуется использовать шлюз API
Шаблон шлюза API также иногда называют "серверной частью для клиентской части" (BFF),
так как она создается с учетом потребностей клиентского приложения.
Таким образом, шлюз API располагается между клиентскими приложениями и микрослужбами.
Он выполняет функцию обратного прокси, передавая запросы от клиентов к службам.
Также он может предоставлять другие сквозные функции, например аутентификацию,
завершение SSL-подключения и кэширование.
Со временем служба шлюза API раздуется из-за этих различных требований и по сути
окажется подобной монолитному приложению или монолитной службе. Поэтому настоятельно
рекомендуется разделять шлюз API между различными службами или между более мелкими шлюзами
API, например по одному шлюзу для каждого типа форм-фактора клиентского приложения.
Следует соблюдать осторожность при реализации шаблона шлюза API. Обычно не рекомендуется
иметь один шлюз API, который агрегирует все внутренние микрослужбы вашего приложения.
Такой шлюз выступает в качестве монолитного агрегатора или оркестратора и нарушает
автономность микрослужб, связывая все микрослужбы друг с другом.
Поэтому шлюзы API следует разделять по границам бизнес-процессов и клиентским приложениям
и не использовать в качестве единого агрегатора для всех внутренних микрослужб.
При разделении уровня шлюза API на несколько шлюзов API, если приложение включает
несколько клиентских приложений, это разделение можно использовать в качестве основы
для описания типов шлюзов API, то есть разработать индивидуальный фасад для каждого
клиентского приложения. Такую схему иногда называют "Серверная часть для клиентской
части" (BFF). Каждый шлюз API может предоставлять различные API с учетом каждого типа
клиентского приложения (а возможно, и форм-фактора), на основе реализации кода адаптера,
который вызывает несколько внутренних микрослужб
Традиционное веб-приложение подключается к микрослужбе MVC, использующей шлюз веб-API.
В примере показана упрощенная архитектура с несколькими детально настроенными шлюзами API.
В этом примере границы для разделения шлюзов API строго основаны на шаблоне
"Серверная часть для клиентской части" (BFF), то есть шлюзы реализуют только те API,
которые нужны конкретному клиентскому приложению. Но в более крупных приложениях следует
пойти немного дальше и использовать границы бизнес-процессов в качестве второго фактора
разделения шлюзов API.

6. Основные возможности шаблона шлюза API
Обратный прокси-сервер или маршрутизация шлюза. Шлюз API предоставляет обратный
прокси-сервер для маршрутизации или перенаправления запросов (маршрутизация уровня 7,
обычно это HTTP-запросы) к конечным точкам внутренних микрослужб. Шлюз предоставляет
единую конечную точку (URL-адрес) для клиентских приложений, а внутри сопоставляет
запросы от них с конкретными группами внутренних микрослужб. Эта возможность
маршрутизации помогает отделить клиентские приложения от микрослужб, но она не менее
удобна при обновлении монолитного API. Между этим монолитным API и клиентскими
приложениями размещается шлюз API, что позволяет добавлять новые API в формате микрослужб
и продолжать использовать монолитный API вплоть до его разделения на множество микрослужб.
Благодаря шлюзу API для клиентских приложений неважно, как реализованы конкретные
API-интерфейсы: в виде внутренних микрослужб или монолитных API. И что более важно,
в процессе развития, рефакторинга и разделения монолитного API на микрослужбы шлюз
API защищает клиентские приложения от любых изменений URI.
-Агрегирование запросов. Шаблон шлюза можно дополнить агрегированием нескольких клиентских
запросов (обычно HTTP-запросов), направленных к разным внутренним микрослужбам,
в один клиентский запрос. Этот шаблон особенно удобен, когда клиенту для отображения
страницы или экрана нужны данные из нескольких микрослужб. При таком подходе клиентское
приложение отправляет на шлюз API один запрос, а шлюз преобразует его в несколько
запросов к внутренним микрослужбам, затем объединяет полученные результаты и отправляет
в клиентское приложение. Основное преимущество и цель этого шаблона разработки
заключается в уменьшении объема данных, передаваемых между клиентскими приложениями
и внутренними API. Это особенно важно для удаленных приложений, размещаемых за пределами
центра обработки данных, где расположены микрослужбы, например для мобильных приложений
или запросов от приложений SPA, созданных на JavaScript в браузерах на удаленном
клиентском компьютере. Для обычных веб-приложений, которые выполняют запросы в серверной
среде (например, веб-приложение ASP.NET Core MVC), этот шаблон менее полезен,
так как сетевая задержка и так намного меньше, чем у удаленных клиентских приложений.
-Проблемы сквозной функциональности или разгрузка шлюза. В зависимости от функций,
предоставляемых конкретной реализацией шлюза API, вы можете перенести некоторые функции
из отдельных микрослужб на шлюз, что упростит реализацию каждой микрослужбы за счет
объединения сквозных функций на отдельном уровне. Это особенно удобно для
специализированных функций, которые иногда сложно правильно реализовать в каждой
внутренней микрослужбе. К этой категории относятся следующие функции:
Аутентификация и авторизация
интеграция средства обнаружения служб;
Кэширование откликов
политики повторных попыток, размыкатель цепи и качество обслуживания;
ограничение скорости и регулирование;
балансировка нагрузки;
ведение журнала, трассировка, корреляция;
преобразования заголовков, строк запроса и утверждений;
Добавление IP-адресов в список разрешений

7. Взаимодействие в архитектуре микрослужб
В монолитном приложении, управляемом единым процессом, компоненты вызывают друг друга
на уровне языка или с помощью вызовов функции. Они могут быть тесно связаны, если вы
создаете объекты с кодом (например, new ClassName()), или могут вызываться несвязанно,
если вы используете внедрение зависимости, ссылаясь на абстракции, а не на конкретные
экземпляры объекта. В любом случае объекты выполняются в одном процессе.
Одно из решений — максимальная изоляция бизнес-микрослужб. В этом случае вы используете
асинхронное взаимодействие между внутренними микрослужбами и заменяете детальное
взаимодействие, типичное для внутрипроцессной связи между объектами, менее детальным.
Для этого вы группируете вызовы и возвращаете клиенту данные, агрегирующие результаты
нескольких внутренних вызовов.
7.1 Типы связи
Клиент и службы могут взаимодействовать через различные типы связи в зависимости от
сценария и целей. Эти типы связи можно разделить на два направления.
Первая группа определяет, является протокол синхронным или асинхронным:
● Синхронный протокол. HTTP — это синхронный протокол. Клиент отправляет запрос и ожидает
ответа от службы. Это не зависит от выполнения кода клиента, которое может быть
синхронным (поток заблокирован) или асинхронным (поток не заблокирован, ответ в
конечном итоге будет отправлен). Здесь важно, что протокол (HTTP/HTTPS) является
синхронным и код клиента сможет продолжить выполнение задачи только после получения
ответа от HTTP-сервера.
● Асинхронный протокол. Другие протоколы, например AMQP (протокол, поддерживаемый
многими операционными системами и облачными средами), используют асинхронные сообщения.
Код клиента или отправитель сообщения обычно не ожидает ответа. Он просто отправляет
сообщение, как при отправке сообщения в очередь RabbitMQ или другого брокера сообщений.
Вторая группа определяет, имеет запрос одного или нескольких получателей:
● Один получатель. Каждый запрос должен обрабатываться только одним получателем или
службой. Например, шаблон Command.
● Несколько получателей. Каждый запрос может обрабатываться разным количеством
получателей — от нуля до нескольких. 
Приложение на базе микрослужб часто использует комбинацию этих стилей взаимодействия.
Наиболее распространенный тип — взаимодействие с одним получателем по синхронному
протоколу, например HTTP или HTTPS, при вызове обычной службы веб-API HTTP.
Для асинхронного взаимодействия между микрослужбами обычно используются протоколы
сообщений.
● Асинхронная интеграция микрослужб способствует их автономности
Если это возможно, никогда не используйте синхронное взаимодействие (запрос-ответ)
между несколькими микрослужбами, даже для запросов. Каждая микрослужба должна быть
автономной и доступной для клиента, даже если другие службы в этом приложении отключены
или не работают. Если вы считаете, что одна микрослужба должна обращаться к другой
(например, отправлять HTTP-запрос на получение данных), чтобы предоставить ответ
клиентскому приложению, вы создадите архитектуру, неустойчивую к сбоям.
Операция запрос-ответ с использованием HTTP и REST
Если клиент использует взаимодействие типа "запрос-ответ", он посылает запрос к службе,
которая обрабатывает этот запрос и отправляет ответ. Взаимодействие типа "запрос-ответ"
особенно хорошо подходит для запроса данных от клиентских приложений для
пользовательского интерфейса в режиме реального времени. Поэтому в архитектуре
микрослужб лучше всего использовать этот механизм взаимодействия для запросов.
Когда клиент использует взаимодействие типа "запрос-ответ", он предполагает,
что ответ придет быстро, меньше чем через секунду или максимум через несколько секунд.
Если ответ задерживается, необходимо реализовать асинхронное взаимодействие на основе
шаблонов обмена сообщениями и технологий обмена сообщениями.
Популярный стиль архитектуры для взаимодействия типа "запрос-ответ" — это REST.
Этот подход основан на HTTP-протоколе и тесно связан с ним. Он принимает HTTP-команды,
например GET, POST и PUT. REST — это самый распространенный архитектурный подход к
взаимодействию при создании служб.

8. Асинхронное взаимодействие на основе сообщений
При использовании системы обмена сообщениями процессы взаимодействуют путем асинхронного
обмена сообщениями. Клиент отправляет команду или запрос в службу при помощи сообщения.
Если служба должна ответить, она отправляет ответное сообщение клиенту. Так как это
взаимодействие на основе сообщений, клиент знает, что ответ может поступить не сразу,
а возможно, что ответа не будет вообще.
Сообщение состоит из заголовка (метаданные, например, идентификатор или данные для
обеспечения безопасности) и текста. Обычно сообщения отправляются с использованием
асинхронного протокола, например AMQP.
Предпочтительной инфраструктурой для такого типа обмена данными в сообществе микрослужб
является упрощенный брокер сообщений, который отличается от больших брокеров и
оркестраторов, используемых в SOA. В случае упрощенного брокера сообщений задача
инфраструктуры обычно сводится к выполнению функций брокера обмена сообщениями с
использованием простой реализации, например RabbitMQ или масштабируемой служебной шины
в облаке, такой как служебная шина Azure. При таком сценарии основная обработка данных
выполняется в конечных точках, там, где создаются и используются сообщения, т. е.
микрослужбами.
Есть еще правило, которого следует придерживаться, насколько это возможно. Между
внутренними службами следует использовать только асинхронный обмен сообщениями,
а синхронное взаимодействие (например, HTTP) использовать только для клиентских
приложений, работающих со службами интерфейса (шлюзами API и микрослужбами первого уровня).
Существует два типа асинхронного обмена сообщениями: взаимодействие на основе сообщений
с одним получателем и взаимодействие с несколькими получателями. В следующих разделах
содержатся дополнительные сведения об этих типах обмена.
● Взаимодействие на основе сообщений с одним получателем
Асинхронное взаимодействие на основе сообщений с одним получателем — это передача данных
от одного узла другому, когда единственный получатель считывает сообщение из канала и
сообщение обрабатывается только один раз. Однако существуют особые случаи. Например, в
облачной системе, когда предпринимаются попытки автоматического восстановления после
сбоя, одно и то же сообщение может быть отправлено многократно. Чтобы быть устойчивым
к сетевым и другим сбоям, клиент должен иметь возможность повторить отправку сообщения,
а сервер должен обеспечить идемпотентность операции, чтобы обработать каждое конкретное
сообщение только один раз.
Взаимодействие на основе сообщений с одним получателем особенно хорошо подходит в
случаях отправки асинхронных команд из одной микрослужбы другую.
После того как вы начнете взаимодействие на основе сообщений (с использованием команд
или событий), вам не следует использовать этот тип взаимодействия вместе с синхронным
обменом по протоколу HTTP.
● Взаимодействие на основе сообщений с несколькими получателями
Существует более гибкий подход. Это механизм публикации или подписки, позволяющий
сделать сообщения от отправителя доступными дополнительным микрослужбам-подписчикам
или внешним приложениям. Он позволяет реализовать принцип "открыт — закрыт" в службе
отправки. Таким образом, в будущем могут быть добавлены дополнительные подписчики
без изменения службы отправителя.
При взаимодействии на основе публикаций и подписок вы, возможно, будете использовать
интерфейс шины событий при публикации событий для всех подписчиков.
● Асинхронное взаимодействие, управляемое событиями
При использовании асинхронного взаимодействия, управляемого событиями, одна микрослужба
публикует событие интеграции, когда что-то происходит внутри ее домена, а другая
микрослужба должна узнать об этом. Пример такого события — изменение цены в микрослужбе
каталога продукции. Дополнительные микрослужбы подписываются на события, что позволяет
им получать данные о них асинхронно. В этом случае получатели могут обновить свои
собственные сущности домена, что может вызвать появление новых событий интеграции,
которые будут опубликованы. Эта система публикаций и подписок реализуется с помощью шины
событий. Шина событий может быть разработана как абстракция или интерфейс с API,
необходимым для подписки и отмены подписки на события и для публикации событий.
Шина событий может иметь одну или несколько реализаций на основе любого межпроцессорного
брокера или брокера обмена сообщениями как очередь сообщений или служебная шина,
поддерживающая асинхронное взаимодействие и модель публикаций и подписок.
В асинхронном взаимодействии на основе событий одна микрослужба публикует события в шине
событий, и многие микрослужбы могут подписаться на нее, чтобы получать уведомления и
реагировать на них. Протокол, используемый для взаимодействия на основе сообщений,
управляемого событиями, зависит от вашей реализации. Протокол AMQP позволяет добиться
надежного взаимодействия с использованием очередей.
При использовании шины событий может возникнуть необходимость использования уровня
абстракции (например, интерфейса шины событий) на основе соответствующей реализации
в классах с кодом, использующим API из брокера сообщений, например RabbitMQ или
служебной шины, такой как служебная шина Azure с разделами. Кроме того, вы можете
использовать более высокий уровень служебной шины, например NServiceBus, MassTransit
или Brighter , для формулировки шины событий и системы публикации и подписки.
