** https://doka.guide/tools/microservices/
Микросервис — это отдельное приложение, как правило, очень небольшое, которое
поддерживает ограниченную функциональность. С помощью программного интерфейса (API)
такое приложение встраивается практически в любой продукт и может работать в составе
разных продуктов одновременно. Микросервисы часто противопоставляют монолитам, крупным
приложениям, которые полностью реализуют большой набор функций. Особенностью монолитов
является глубокое зацепление разных частей приложения и, как следствие, худшие
характеристики масштабируемости в сравнении с микросервисами.
Например, приложение, которое рассылает письма по списку адресов электронной почты,
или приложение, которое проводит аутентификацию пользователей, или приложение,
которое отслеживает активность пользователей в сервисе, — отличные кандидаты,
чтобы стать микросервисами. Можно повторять разработку похожего набора функций
для нового продукта, а можно реализовать и отладить микросервис или несколько
микросервисов, которые будут работать корректно для любого приложения.
Традиционно существовала концепция приложения, которое полностью решает все задачи
программного продукта — монолит. В эпоху быстрого развития рынка IT стало важным
уменьшить показатель time-to-market — время доведения до потребителя новой
функциональности или продукта. 
Практика разбиения программ на модули, которые можно переиспользовать в других программах,
оказалась успешной. Сначала на стороне сервера (бэкенд), потом и на стороне клиента
(фронтенд), части приложения стали выносить не только в отдельные модули, но и в
отдельные самостоятельные программы. Это позволило переиспользовать прошедшую проверку
временем функциональность в новых продуктах. Так и пришли к новому понятию — микросервис.

Плюсы микросервисов:
● Можно использовать тот стек технологий, который больше всего подходит для решения
поставленной задачи.
● Проще и дешевле разрабатывать набор микросервисов, в сравнении с разработкой
большого приложения.
● Поддерживать микросервисы намного проще и дешевле, чем поддерживать большое приложение.
● Не приходится каждый раз отлаживать работу для новых продуктов.
● Легко масштабировать приложение, построенное как совокупность микросервисов.
● Отказ одного сервиса не приводит к остановке системы в целом. Когда же ошибка
исправлена, необходимое изменение можно развернуть только для соответствующего
сервиса — вместо повторного развертывания всего приложения.
● Есть возможность использовать разные подходы к тестированию и доработки
каждого микросервиса.

Минусы микросервисов:
● Нужно поддерживать контракт — формализацию возможностей и условий взаимодействия
с микросервисом.
● Должна быть достаточно высокой квалификация разработчиков и инженеров по инфраструктуре.
● Микросервис должен минимально зависеть от контекста использования, не всегда это возможно.
● Могут возникать коллизии при обращении к одним и тем же сервисам: к базе данных,
к оперативной памяти, к диску, к процессору и прочим ресурсам.
● Сложно поддерживать и тестировать большое количество микросервисов.
● Разрабатывать большое количество микросервисов иногда дороже разработки монолита.

Когда применять
● Нужно держать высокую нагрузку. Проблемы пикового трафика легко решаются с помощью
микросервисов, существуют готовые решения и облачные сервисы, которые обеспечивают
автомасштабирование приложения. Сервисы добавляют ресурсы нагруженным микросервисам
или создают копии.
● Выросла команда разработки. Команда уже больше 10-15 человек и постоянно растёт,
новичков становится сложнее погружать во все тонкости разработки. Микросервисы могут
упростить командную работу и привести к единому набору стандартов разработки.
● В приложении появилось много модулей. Модулей уже несколько десятков, они достаточно
автономны, перевод их в микросервисы позволит легче масштабировать приложение
в будущем или переиспользовать при разработке новых продуктов.
● Стало очень много кода. Если приложение становится очень большим, то разбиение на
микросервисы упростит его поддержку и развитие.
● Нужно загружать приложение быстрее. Если приложение запускается несколько минут,
микросервисы позволят оптимизировать загрузку и применить масштабирование для
непроизводительных или высоконагруженных частей программы. Кроме этого, разработчики
тоже не будут ждать длительной сборки приложения и его загрузки на этапе отладки.
● Нужно использовать ресурсы компьютера оптимально. Модули могут обращаться к сети,
к памяти или к процессору неравномерно. Применение микросервисов позволит
оптимизировать этот компонент в работе приложения.
● Нужно быстро выводить новые продукты на рынок. Нужно обеспечить минимальное время
выхода на рынок новых продуктов и новых функций для уже существующих, микросервисы
обеспечат максимальную скорость развёртывания.

https://mcs.mail.ru/blog/prostym-jazykom-o-mikroservisnoj-arhitekture
Микросервисы и SOA не одно и то же. К SOA относится множество других шаблонов,
среди которых: CORBA, web-сервисы, очереди сообщений, ESB. Поэтому микросервисы стоит
воспринимать как конкретный подход к SOA, но не единственный.
Рассмотрим для примера типичный интернет-магазин. Монолитное приложение для него будет
использовать наверняка знакомую вам трехуровневую архитектуру, включающую:
1. пользовательский интерфейс;
2. серверную часть, отвечающую за бизнес-логику приложения и доступ к данным;
3. базу данных.
Мы видим, что бизнес-функции приложения очень разнообразны: работа с каталогом товаров
и корзиной, обработка заказов, их оплата и отслеживание статуса, ведение пользователей
и так далее. Но на уровне приложения все они объединены в один монолитный блок.
При разворачивании код для различных функций находится на одном сервере.
Чтобы масштабировать приложение, вам необходимо запустить несколько его экземпляров
на различных физических серверах.
Если монолитное приложение проще всего сравнить с кирпичной кладкой, то микросервисы
похожи на всем знакомый конструктор Lego. У вас есть множество деталей с четкими
стандартными границами для соединения друг с другом. Вы всегда можете пересобрать
получившееся изделие, заменив или убрав какие-то из элементов без ущерба для остальных.
Каждый из сервисов отвечает за конкретную бизнес-задачу, имеет собственное хранилище
данных и общается с другими сервисами через простые API-интерфейсы для решения более
сложных задач. Так, в нашем примере можно выделить микросервисы по ведению каталога
товаров, работе с корзиной, оформлению заказов, оплате и так далее.

https://cloud.yandex.ru/blog/posts/2022/03/microservice-architecture
Какие инструменты использовать для создания микросервисов и работы с ними
1. Один из самых популярных способов создавать микросервисы — платформа контейнеризации
Docker. С его помощью приложение отделяется от инфраструктуры: это значит, что вы
сможете беспроблемно перемещаться между облачным и локальным хранилищем.
2. Чтобы оркестрировать контейнеры, то есть управлять работой с ними, чаще всего
используют кластеры Kubernetes.
3. Неотъемлемая часть любого микросервисного проекта — балансировщик.
Именно благодаря ему такую архитектуру считают более устойчивой к отказам,
чем монолитную: он контролирует, чтобы нагрузка на приложение распределялась по
облачным ресурсам равномерно.
** https://habr.com/ru/company/vk/blog/320962/
Микросервисная архитектура — это подход к созданию приложения, подразумевающий отказ
от единой, монолитной структуры. То есть вместо того чтобы исполнять все ограниченные
контексты приложения на сервере с помощью внутрипроцессных взаимодействий,
мы используем несколько небольших приложений, каждое из которых соответствует какому-то
ограниченному контексту. Причём эти приложения работают на разных серверах и
взаимодействуют друг с другом по сети, например посредством HTTP.
Иными словами, мы инкапсулируем определённые контексты приложения в микросервисы,
по одному на каждый, а сами микросервисы крутим на разных серверах.

Непрерывное развёртывание
Возможность и нацеленность на постоянное ускорение работы
● Быстро вводить в эксплуатацию: быстро развёртывать новые машины для разработки,
тестирования, приёмки и работы.
● Быстро развёртывать приложения: автоматически и быстро развёртывать наши сервисы.

Опять же, в старые добрые времена компании использовали архитектуру
Enterprise Service Bus (сервисная шина), при которой формируется канал коммуникаций
между эндпойнтами и бизнес-логикой. Затем этот подход преобразился в spaghetti box.
Микросервисная архитектура переносит бизнес-логику в конечные точки и использует
простые способы взаимодействия вроде HTTP.

Фронтенд/бэкенд
Есть два подхода к структурированию фронтенда и бэкенда при микросервисной архитектуре:

● Раскидать все части пользовательского интерфейса по микросервисам и сохранять
взаимосвязи между соответствующими микросервисами. Это позволяет наладить
внутрипроцессное взаимодействие между фронтендом и бэкендом. Но тогда будет очень сложно,
если вообще возможно, поддерживать связность UI. В случае перекрёстных изменений границ
в UI нам придётся одновременно обновлять несколько микросервисов, создавая взаимосвязи
и нарушая изолированность и независимость микросервисов, обеспечиваемые самой
архитектурой. Получается практически антипаттерн!
● Раскидать кодовые базы фронтенда и бэкенда, оставив UI приложения одним целым,
чтобы они потом взаимодействовали по HTTP. Микросервисы будут отделены друг от друга,
что дополнительно разделит фронтенд и бэкенд. Зато UI можно поддерживать целиком,
легко сохраняя его связность.

** https://habr.com/ru/post/249183/
Термин «Microservice Architecture» получил распространение в последние несколько лет
как описание способа дизайна приложений в виде набора независимо развертываемых сервисов.
В то время как нет точного описания этого архитектурного стиля, существует некий общий
набор характеристик: организация сервисов вокруг бизнес-потребностей, автоматическое
развертывание, перенос логики от шины сообщений к приемникам (endpoints) и
децентрализованный контроль над языками и данными.
архитектурный стиль микросервисов — это подход, при котором единое приложение строится
как набор небольших сервисов, каждый из которых работает в собственном процессе и
коммуницирует с остальными используя легковесные механизмы, как правило HTTP.
Эти сервисы построены вокруг бизнес-потребностей и развертываются независимо с
использованием полностью автоматизированной среды.

Архитектура микросервисов использует библиотеки, но их основной способ разбиения
приложения — путем деления его на сервисы. Мы определяем библиотеки как компоненты,
которые подключаются к программе и вызываются ею в том же процессе, в то время как
сервисы — это компоненты, выполняемые в отдельном процессе и коммуницирующие между
собой через веб-запросы или remote procedure call (RPC).
Главная причина использования сервисов вместо библиотек — это независимое развертывание.
Если вы разрабатываете приложение, состоящее из нескольких библиотек, работающих
в одном процессе, любое изменение в этих библиотеках приводит к переразвертыванию
всего приложения. Но если ваше приложение разбито на несколько сервисов, то изменения,
затрагивающие какой-либо из них, потребуют переразвертывания только изменившегося сервиса.
Конечно, какие-то изменения будут затрагивать интерфейсы, что, в свою очередь,
потребует некоторой координации между разными сервисами, но цель хорошей архитектуры
микросервисов — минимизировать необходимость в такой координации путем установки
правильных границ между микросервисами, а также механизма эволюции контрактов сервисов.

Микросервисный подход к разбиению подразумевает разбиение на сервисы в соответствии
с потребностями бизнеса. Такие сервисы включают в себя полный набор технологий,
необходимых для этой бизнес-потребности, в том числе пользовательский интерфейс,
хранилице данных и любые внешние взаимодействия. Это приводит к формированию
кросс-функциональных команд, имеющих полный набор необходимых навыков:
user-experience, базы данных и project management.

При выстраивании коммуникаций между процессами мы много раз были свидетелями того,
как в механизмы передачи данных помещалась существенная часть логики.
Хорошим примером здесь является Enterprise Service Bus (ESB).
ESB-продукты часто включают в себя изощренные возможности по передаче, оркестровке
и трансформации сообщений, а также применению бизнес-правил.
Комьюнити микросервисов предпочитает альтернативный подход: умные приемники сообщений
и глупые каналы передачи.
Вместо сложных протоколов, таких как WS-* или BPEL, они используют простые
REST-овые протоколы.
Два наиболее часто используемых протокола — это HTTP запросы через API ресурса
и легковесный месседжинг. легковесная шина сообщений. Такая инфраструктура как правило
не содержит доменной логики — простые реализации типа RabbitMQ или ZeroMQ не делают
ничего кроме предоставления асинхронной фабрики. Логика при этом существует на концах
этой шины — в сервисах, которые отправляют и принимают сообщения.

** https://habr.com/ru/company/maxilect/blog/677128/ Способы общения микросервисов
Синхронные способы общения - мы делаем вызов и ждем получения ответа:

* Синхронный REST-like и аналоги. В чистом виде REST встречается редко, но в целом он
один из самых популярных. При желании через костыли его можно сделать “асинхронным”,
но этот случай мы тут не будем рассматривать.
● gRPC - RPC на бинарном формате сообщений поверх HTTP/2 от Google.
● SOAP - RPC с форматом XML. Это решение очень любили использовать в энтерпрайзе, оно
чаще встречается в более старых системах.

* Асинхронные способы общения - мы отправляем сообщение, а ответ придет когда-нибудь
потом или он в принципе не предусмотрен:
● Месседжинг - RabbitMQ, ZeroMQ, ActiveMQ.
● Стриминг - Kafka. 

REST API
90% сервисов работает на REST API. Его так любят, потому что:
● Нужен минимум библиотек как клиенту, так и серверу. HTTP у нас и так работает,
в JSON можно писать / читать string.
● Легко вызвать API с фронта, легко прочитать ответ сервера из JS с помощью JSON.parse().
● Легкий старт для потребления API - узнал endpoint, посмотрел пример
запроса / ответа и можно начинать общение.
● Текстовый формат - легко дебажить и логировать, видя, что у него внутри в сообщении.
● Админы любят - можно заглядывать в данные HTTP-запроса и что-то с ними делать,
например настраивать роутинг трафика на основе данных http-запросов (L7)
или балансировку нагрузки по полю ID из запроса.
● Легкая для понимания синхронная парадигма “запрос-ответ”. Здесь нет подводных камней.
Ответ либо получен тут же, либо нет.
Но во всей этой простоте есть свои проблемы. Каждая из особенностей REST API,
которая делает его столь простым и популярным, на самом деле имеет оборотную сторону:
● Синхронный - если вызываемый сервис недоступен, нельзя отложить передачу или получение
информации на более позднее время. Если какой-то простой batch должен передать
сообщение и завершиться, но получатель лежит, будут проблемы.
● Peer-to-peer - нужно обращаться напрямую к искомому сервису. Более того, здесь нет
броадкастинга - если надо отправить одни и те же данные в пять разных сервисов,
придется сделать пять запросов. Сервисы получаются более связанными и могут погибать
в “волне отказов”.
● Текстовый - в JSON много лишних данных (ключи - значения), которые порождают
дополнительный трафик. Компрессия не позволяет сжать так, как хотелось бы, плюс
потребляет процессор. Для экономии некоторые пытаются называть ключи компактнее,
но глобально это не решает проблему.
● Нет схемы данных - вместо нее используют OpenAPI (Swagger), но он внедряется
не всегда и в целом это лишь свод рекомендаций, а не четкий закон.
Он может не соответствовать действительности.
● Концепция “все есть ресурс” может быть неудобна и непонятна части разработчиков.
Лично мне не нравится, что не все задачи легко решаются в рамках этой концепции.
Иногда не совсем понятно, как все уложить в понятие ресурса.
Есть уже прижившиеся способы описывать разные проблемные случаи,
вроде изменений статусов объектов. Но фактически это костыли.
● REST API - неплохое решение, когда нет высоких нагрузок и получается хорошо
контролировать доступность микросервисов. Взаимодействия по REST API проще отслеживать,
чем асинхронный обмен, - сразу видно, что ответ не приходит или приходит не в том формате.

gRPC:
● Использует бинарный формат Protobuf - утилизация трафика лучше, можно слать только
значения, не передавая ключи. Конечно, ты не можешь прочитать в консоли сообщение
глазами, как мог бы это сделать с JSON (приходится писать дополнительную утилиту,
которая будет его парсить перед тем, как прочитать). Зато на больших нагрузках
все это будет лучше работать.
● Есть схема данных, по которой генерируется DTO на запрос / ответ.
С жесткой схемой работать удобнее, Protobuf накладывает ограничения на изменение
схемы данных, чтобы сохранялась обратная совместимость. Это и плюс, и иногда минус.
● Можно передавать не один запрос, а слать объекты один за другим - стримить
● Есть встроенный механизм backpressure - если сообщения отправляются слишком быстро
и получатель не может их “переварить”, этот механизм позволяет замедлить передачу.
● Отправка запроса выглядит, как вызов метода в коде, - используется RPC-стиль.
gRPC подходит, если у вас в облаке крутится целый комбайн из кучи микросервисов,
которым надо между собой передавать много данных под высокой нагрузкой.
Для внешних пользователей он, конечно, не так удобен, как REST, но для внутреннего
общения это самое то, потому что здесь жестко фиксируется схема и потребляется меньше
трафика

Мессенджинг - RabbitMQ, ZeroMQ, ActiveMQ и Kafka:
Все перечисленные инструменты занимаются отправкой сообщений. Они очень разные,
но в целом верно следующее:
● Они обычно асинхронные. Шлешь сообщение и оно доставится когда-то в будущем.
Никакого “запрос-ответ”. Есть решения, где прямой очереди соответствует обратная
очередь для отправки ответа на сообщение, но это нельзя назвать синхронной историей.
● Бывают с брокером и без него. С моей точки зрения именно брокер дает слабую
связанность общению, правда, бывают кейсы, где все это реализуется очень медленно.
Поэтому брокер иногда считается оверхедом.
● С хранилищем (persistence) и без него (in-memory). В случае отказа брокер с хранилищем
(например, Kafka), который пишет все сразу на диск, ничего не потеряет. Правда, только
при условии, что вы позаботились настроить кластер как следует. Так можно хранить логи,
например за последние полгода. Но при чтении старых данных с диска все подтормаживает.
● С балансировкой нагрузки и без.
● Текстовые и бинарные.
● Со схемой данных или без нее.
● С одним получателем или с поддержкой броадкаста. Если честно, возможность броадкастинга
мне нравится больше всего - ты можешь реализовать модель издатель-подписчик,
когда тебе не интересно, кто подписался на тему. Твоя задача просто писать в нее
сообщения.
● С подтверждением получения и без него.
Kafka и прочие перечисленные инструменты - это дополнительный слой абстракции,
который обеспечивает асинхронность и отказоустойчивость. Он хорошо работает там,
где все это действительно востребовано - в сложной архитектуре с большим количеством
исполнителей, которых хочется подключать и отключать. Kafka умеет следить за тем,
чтобы сообщения не терялись, правильно все распараллеливать и реплицировать,
занимается дедупликацией при необходимости.
Оборотная сторона медали в том, что в асинхронном взаимодействии сложнее разобраться.
Ответ не приходит сразу - он может не прийти вообще или появиться через несколько часов
в ответном топике. У нашей команды множество историй про Kafka, в том числе и связанных
с багами самой Kafka. Кажется, что у любого разработчика есть свои примеры странного
поведения брокера.
